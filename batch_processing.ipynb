{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing!\n",
    "#### A notebook to show some of the capilities available through the pCunch package\n",
    "\n",
    "This is certainly not an exhaustive look at everything that the pCrunch module can do, but should hopefully provide some insight. \n",
    "...or, maybe I'm just procrastinating doing more useful work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Modules and instantiation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "# %matplotlib widget\n",
    "# ROSCO toolbox modules \n",
    "from ROSCO_toolbox import utilities as rosco_utilities\n",
    "# WISDEM modules\n",
    "from wisdem.aeroelasticse.Util import FileTools\n",
    "# Batch Analysis tools\n",
    "from pCrunch import Processing, Analysis\n",
    "from pCrunch import pdTools\n",
    "\n",
    "# Instantiate fast_IO\n",
    "fast_io = rosco_utilities.FAST_IO()\n",
    "fast_pl = rosco_utilities.FAST_Plots()\n",
    "\n",
    "import importlib\n",
    "Processing = importlib.reload(Processing)\n",
    "Analysis = importlib.reload(Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define file paths and filenames\n",
    "I'm loading a case matrix output from using wisdem.aeroelasticse.CaseGen_General to run a series of batch runs to initialize the output files here. I'm just using some saved runs on my computer that are of no actual significants (and actually don't look great, but get the point accross)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to some file paths\n",
    "outfile_base = '../BatchOutputs/NREL5MW/5MW_Land/'\n",
    "fname_case_matrix = '../BatchOutputs/NREL5MW/5MW_Land/case_matrix.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load case matrix into datafraome\n",
    "case_matrix = FileTools.load_yaml(fname_case_matrix, package=1)\n",
    "cm = pd.DataFrame(case_matrix)\n",
    "# cm[cm[('IEC','DLC')]=='1.1']\n",
    "_, _, _, cmw = Processing.get_windspeeds(cm, return_df=True)\n",
    "cmw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define DLCs we care to separate things by\n",
    "DLCs = [1.1, 1.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pare down case matrix for desired runs and load the outfiles\n",
    "cm2 = pd.concat([cm[cm[('IEC','DLC')]==dlc] for dlc in DLCs]).reset_index()\n",
    "\n",
    "# Parse find outfiles names\n",
    "outfiles = []\n",
    "for dlc in DLCs:\n",
    "    case_names = cm2[cm2[('IEC','DLC')]==dlc]['Case_Name']\n",
    "    outnames = list( outfile_base + case_names + '.outb' )\n",
    "    outfiles.append(outnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### `outfiles`\n",
    "In the end, we just need a list of OpenFAST output files. Here, we have a structure that looks something like `[[], []]`. This could be extended any amount like `[[],[],...,[], []]`, or just be one list of strings `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can do some processing!\n",
    "\n",
    "First, let's load the FAST_Processing class and initialize some parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = Processing.FAST_Processing()\n",
    "fp.OpenFAST_outfile_list = outfiles\n",
    "fp.dataset_names = ['DLC1.1', 'DLC1.3']\n",
    "fp.to = 30\n",
    "fp.parallel_analysis = True\n",
    "fp.save_LoadRanking = True\n",
    "fp.save_SummaryStats = True\n",
    "fp.verbose=True\n",
    "# fp.ranking_vars = [[\"RotSpeed\"], \n",
    "#                     [\"OoPDefl1\", \"OoPDefl2\", \"OoPDefl3\"], \n",
    "#                     ['RootMxc1', 'RootMxc2', 'RootMxc3'],\n",
    "#                     ['TwrBsFyt'],\n",
    "#                     ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fast way to compare things.\n",
    "We could now collect all of the summary stats and load rankings using:\n",
    "```\n",
    "stats,load_rankings = fp.batch_processing()\n",
    "```\n",
    "In `fp.batch_processing()` most of the analysis is done for any structure of data. I'm going to step through things a bit more piecewise in this notebook, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats,load_rankings = fp.batch_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Comparisons\n",
    "We can use fp.design_comparison to compare multiple sets of runs (like we are in this case...). This will generate summary stats and load rankings, running parralelizing when it can and is told to. `fp.batch_processing()` functionally does the same thing. We'll the design comparison here to show some speed-related results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats, load_ranking = fp.design_comparison(outfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking it down further...\n",
    "\n",
    "`fp.batch_processing()` calls `Analysis.Loads_Analysls.full_loads_analysis()` to load openfast data, generate stats, and calculate load rankings. Because we defined `fp.parallel_analysis=True` this process was parallelized. This helps for speed and memory reasons, because now every openfast run is not saved. `fp.batch_processing()` then takes all of the output data and parses it back together. \n",
    "\n",
    "Separately, we call call `Analysis.Loads_Analysls.full_loads_analysis()` with `return_FastData=True` and all of the fast data will be returned. Because we are comparing data though, we'll stick with the design comparison tools.\n",
    "\n",
    "### We can look at our data a bit further with pandas dataframes\n",
    "The data here is just for a few runs for simplicity. Usually you'd do this for a LOT more cases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pdTools.dict2df(stats, names=['DLC_1.1', 'DLC_1.3'])\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Ranking\n",
    "Lets re-run the load ranking for the sake of example. We'll have to load the analysis tools, and then run the load ranking for the stats we just "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = Analysis.Loads_Analysis()\n",
    "fa.t0 = 30\n",
    "fa.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the ranking variables and statiscits of interest. Note that `len(ranking_vars) == len(ranking_stats)`! We can pass this a list of stats (multiple runs), a dictionary with one run of stats, or a pandas dataframe with the requisite stats. We'll also output a dictionary and a pandas DataFrame from `fa.load_ranking()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.ranking_vars = [['TwrBsFyt'], ['OoPDefl1', 'OoPDefl2', 'OoPDefl3']]\n",
    "fa.ranking_stats = ['max', 'min']\n",
    "load_ranking, load_ranking_df = fa.load_ranking(stats_df, get_df=True)\n",
    "load_ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is organized for each iteration of `[ranking_vars, ranking_stats]`. The stats are ordered accordingly, and `(stat)_case_idx` refers to the case name index of each load. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot load ranking\n",
    "We can plot the load ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Processing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4063060b0c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwindspeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIECtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_windspeeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Plot bar charts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflag_DLC_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_ranking\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Processing' is not defined"
     ]
    }
   ],
   "source": [
    "windspeed, seed, IECtype, cmw = Processing.get_windspeeds(cm[0], return_df=True)\n",
    "\n",
    "# Plot bar charts\n",
    "flag_DLC_name = True\n",
    "n_ranking     = 10\n",
    "fig_ext       = '.pdf'\n",
    "font_size     = 10\n",
    "\n",
    "clrs = np.array([[127, 60, 141],\n",
    "                 [17, 165, 121],\n",
    "                 [57, 105, 172],\n",
    "                 [242, 183, 1],\n",
    "                 [231, 63, 116],\n",
    "                 [128, 186, 90],\n",
    "                 [230, 131, 16]]) / 256.\n",
    "\n",
    "for k in range(int(0.5 * len(load_ranking_df.columns))):\n",
    "    ch_i = int(k*2)\n",
    "    colors = np.zeros((n_ranking, 3))\n",
    "    case   = load_ranking_df.columns[ch_i][0]\n",
    "    channel= load_ranking_df.columns[ch_i][1]\n",
    "    stat   = load_ranking_df.columns[ch_i][2]\n",
    "    labels = n_ranking * ['']\n",
    "    for i in range(n_ranking):\n",
    "        DLC_class = cm[0][('IEC', 'DLC')][load_ranking_df[case][channel][stat + '_case_idx'][i]]\n",
    "        if DLC_class == '1.1':\n",
    "            colors[i,:] = clrs[0]\n",
    "        elif DLC_class == '1.3':\n",
    "            colors[i,:] = clrs[1]\n",
    "        elif DLC_class == '1.4':\n",
    "            colors[i,:] = clrs[2]\n",
    "        elif DLC_class == '1.5':\n",
    "            colors[i,:] = clrs[3]\n",
    "        elif DLC_class == '5.1':\n",
    "            colors[i,:] = clrs[4]\n",
    "        elif DLC_class == '6.1':\n",
    "            colors[i,:] = clrs[5]\n",
    "        elif DLC_class == '6.3':\n",
    "            colors[i,:] = clrs[6]\n",
    "        else:\n",
    "            colors[i,:] = clrs[7]\n",
    "\n",
    "        WS    = windspeed[load_ranking_df[case][channel][stat + '_case_idx'][i]]\n",
    "        labels[i] = 'DLC ' + DLC_class +' - ' + str(WS) + ' m/s'\n",
    "        labels_index = load_ranking_df[case][channel][stat + '_case_idx'][0:n_ranking]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    load_ranking_df[case][channel][stat][0:n_ranking].plot.bar(color=colors)\n",
    "    plt.xlabel('DLC [-]', fontsize=font_size+2, fontweight='bold')\n",
    "    plt.ylabel(channel + ' ' + uom[k], fontsize=font_size+2, fontweight='bold')\n",
    "    if flag_DLC_name:\n",
    "        plt.xticks(np.arange(n_ranking), labels=labels)\n",
    "    else:\n",
    "        plt.xticks(np.arange(n_ranking), labels=labels_index)\n",
    "    plt.subplots_adjust(bottom = 0.5, left = 0.2)\n",
    "    #fig.savefig(output_folder + 'ranking_' + case + '_' + channel + '_' + stat + fig_ext)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind speed related analysis\n",
    "We often want to make sense of some batch output data with data binned by windspeed. We can leverage the case-matrix from our output data to figure out the input wind speeds. Of course, `('InflowWind', 'Filename')` must exist in the case matrix. Lets load the wind speeds, save them, and append them to the case matrix as `('InflowWind', 'WindSpeed')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed, seed, IECtype, cmw = Processing.get_windspeeds(cm2, return_df=True)\n",
    "cmw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AEP\n",
    "Now that we know the wind speeds that we were operating at, we can find the AEP. We define the turbine class here, and the cumulative distribution or probability density function \n",
    "for the Weibull distribution per IEC 61400 is generated. We can then calculate the AEP. \n",
    "\n",
    "If we first want to verify the PDF, we initialize the `power_production` function, define the turbine class, and can plot a CDF for given range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Analysis.Power_Production()\n",
    "pp.turbine_class = 2\n",
    "Vrange = np.arange(2,26) # Range of wind speeds being considered\n",
    "weib_prob = pp.prob_WindDist(Vrange,disttype='pdf')\n",
    "plt.close('all')\n",
    "plt.plot(Vrange, weib_prob)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Wind Speed m/s\")\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probability Density Function \\n IEC Class 2 Wind Speeds ')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the AEP, we need to provide the wind speeds that the simulations were run for, and the corresponding average power results. Internally, in power_production.AEP, the mean power for a given average wind sped is multiplied times the wind speed's probability, then extrapolated to represent yearly production. \n",
    "\n",
    "To get the AEP, the process is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AEP = pp.AEP(stats, windspeed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### About the wind speed warning:\n",
    "Here, we get a warning about the input windspeed array. This is because we passed the complete array output from Processing.get_windspeeds to the AEP function. The input windspeeds to power_production.AEP must satisfy either of the following two conditions:\n",
    "- each wind speed value corresponds to each each statistic value, so `len(windspeeds) = len(stats_df)`\n",
    "- each wind speed value corresponds to each run in the case matrix, so `len(windspeeds) = len(cm)`\n",
    "\n",
    "If the second of these conditions is satisfied, it is assumed that each dataset has the same wind speeds corresponding to each run. So, in this case, the wind speeds corresponding to DLC_1.1 and DLC_1.3 should be the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Finally, we can make some plots. There are a few tools we have at our disposal here. First, we can look at more plots that show our design performance as a function of wind speed. Notably, we can pass the stats dictionary or dataframe to these statistics-related scripts.\n",
    "\n",
    "Currently, `an_plts.stat_curve()` can plot a \"statistics curve\" for of two types, a bar or a line graph. \n",
    "\n",
    "A bar graph is useful to compare design cases easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "an_plts = Analysis.wsPlotting()\n",
    "an_plts.stat_curve(windspeed, stats, 'RotSpeed', 'bar', names=['DLC1.1', 'DLC1.3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line graph can be useful to show turbulent wind curves. Here we show the means with a first level of errorbars corresponding to standard deviations, and a second level showing minimums and maximums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_plts.stat_curve(windspeed, stats, 'GenPwr', 'line', stat_idx=1, names=['DLC1.3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time domain related data\n",
    "We can also look at our data from the time domain results. \n",
    "\n",
    "We can compare any number of channels using the ROSCO toolbox plotting tools. First we'll load two cases to plot together, then plot the time histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load some time domain cases \n",
    "filenames = [outfiles[0][7], outfiles[1][7]] # select the 2nd run from each dataset\n",
    "fast_data = fast_io.load_FAST_out(filenames, tmin=30)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the plots we want to make (can be as many or as few channels and plots as you would like...)\n",
    "cases = {'Baseline': ['Wind1VelX', 'GenPwr', 'BldPitch1', 'GenTq', 'RotSpeed'],\n",
    "        'Oop' : ['OoPDefl1', 'OoPDefl2', 'OoPDefl13']}\n",
    "\n",
    "# plot\n",
    "fast_pl.plot_fast_out(cases, fast_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can additionally do some frequency domain analysis. Here, `spec_cases` is defined by `(channel, run)` where the run index corresponds to the desired plotting index in the loaded fast data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_cases = [('RootMyb1', 0), ('', 0)]\n",
    "twrfreq = .0716\n",
    "fig, ax = fast_pl.plot_spectral(fast_data, spec_cases, \n",
    "                                show_RtSpeed=True, RtSpeed_idx=[0],\n",
    "                                add_freqs=[twrfreq], add_freq_labels=['Tower'],\n",
    "                                averaging='Welch')\n",
    "ax.set_title('DLC_1.1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the distribution of any channels from our fast output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_plts = Analysis.wsPlotting()\n",
    "channels = ['RotSpeed']\n",
    "caseid = [0,1]\n",
    "an_plts.distribution(fast_data, channels, caseid, names=['DLC 1.1', 'DLC 1.3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AEP Stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vavg = 10\n",
    "\n",
    "windspeeds = np.array([1.,2.,3.,3.,5.])\n",
    "ws_set = list(set(windspeeds))\n",
    "ptemp = np.random.rand(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ptemp.T)\n",
    "df['windspeeds'] = windspeeds\n",
    "df = df.groupby('windspeeds').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.trapz(df.T * ws_set, ws_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['windspeeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}